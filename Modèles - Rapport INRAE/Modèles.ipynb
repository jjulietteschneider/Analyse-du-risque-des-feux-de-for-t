{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a384960-ee4d-4594-ad92-01e39f583e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40b69cd-10eb-47b0-8284-95468638707d",
   "metadata": {},
   "source": [
    "## 1- Modèle GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a604f8f-4aea-4cd7-971e-bace00a42c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('X.csv')\n",
    "Y = pd.read_csv('Y.csv')\n",
    "\n",
    "X['maille_safran'] = X['maille_safran'].astype(str)\n",
    "Y['Mailles'] = Y['Mailles'].astype(str)\n",
    "Y.rename(columns={'Mailles': 'maille_safran', 'Année': 'Année'}, inplace=True)\n",
    "\n",
    "X['maille_safran'] = X['maille_safran'].astype(int)\n",
    "Y['maille_safran'] = Y['maille_safran'].astype(float).astype(int)\n",
    "\n",
    "data = pd.merge(X, Y, on=['maille_safran', 'Année'], how='inner')\n",
    "data['IFM_moy'] = data.iloc[:, 2:32].mean(axis=1)  #On regresse sur ça mais je capte pas bien ce que c'est\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4db61fd-8df7-420f-a9f0-e638e2510968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:        Q(\"Feu en été\")   No. Observations:                 2448\n",
      "Model:                            GLM   Df Residuals:                     2446\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                   -inf\n",
      "Date:                Thu, 18 Apr 2024   Deviance:                       4991.0\n",
      "Time:                        16:28:05   Pearson chi2:                 2.68e+03\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.5263      0.087      6.030      0.000       0.355       0.697\n",
      "IFM_moy       -0.0166      0.010     -1.705      0.088      -0.036       0.002\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.11/site-packages/statsmodels/genmod/generalized_linear_model.py:1891: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  prsq = 1 - np.exp((self.llnull - self.llf) * (2 / self.nobs))\n"
     ]
    }
   ],
   "source": [
    "# Modèle GLM avec lien logit\n",
    "model = smf.glm(formula='Q(\"Feu en été\") ~ IFM_moy', data=data, family=sm.families.Binomial())\n",
    "result = model.fit()\n",
    "\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d0158-b47d-47c9-a370-e88370a8828e",
   "metadata": {},
   "source": [
    "# 2 - Train/Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7fc9ef-1074-4145-a753-c940e5290bfa",
   "metadata": {},
   "source": [
    "## a. Regression Logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb0787-3eed-4550-ad56-ea9f5568e9db",
   "metadata": {},
   "source": [
    "# les différents modèles qu'on pourrait essayer de tester??\n",
    "\n",
    "SVM (Support Vector Machine) : Les SVM sont également populaires pour la classification binaire. Ils sont efficaces dans les espaces de grande dimension et peuvent bien fonctionner avec des données numériques.\n",
    "\n",
    "Forêts aléatoires (Random Forests) : Les forêts aléatoires sont une extension des arbres de décision et sont moins sensibles au surajustement. Elles sont robustes et peuvent gérer de grandes quantités de données.\n",
    "\n",
    "Réseaux de neurones artificiels (Neural Networks) : Les réseaux de neurones peuvent être très puissants pour la classification binaire, mais ils peuvent nécessiter plus de données et de ressources de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04fa03f9-3c7e-4318-b652-c21558e55f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On merge les deux tables\n",
    "X = pd.read_csv('X.csv')\n",
    "Y = pd.read_csv('Y.csv')\n",
    "\n",
    "X['maille_safran'] = X['maille_safran'].astype(str)\n",
    "Y['Mailles'] = Y['Mailles'].astype(str)\n",
    "Y.rename(columns={'Mailles': 'maille_safran', 'Année': 'Année'}, inplace=True)\n",
    "\n",
    "X['maille_safran'] = X['maille_safran'].astype(int)\n",
    "Y['maille_safran'] = Y['maille_safran'].astype(float).astype(int)\n",
    "\n",
    "data = pd.merge(X, Y, on=['maille_safran', 'Année'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02e6826b-7656-42a9-a1b6-9cf8983e0dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maille_safran</th>\n",
       "      <th>01 Jun</th>\n",
       "      <th>02 Jun</th>\n",
       "      <th>03 Jun</th>\n",
       "      <th>04 Jun</th>\n",
       "      <th>05 Jun</th>\n",
       "      <th>06 Jun</th>\n",
       "      <th>07 Jun</th>\n",
       "      <th>08 Jun</th>\n",
       "      <th>09 Jun</th>\n",
       "      <th>...</th>\n",
       "      <th>23 Aug</th>\n",
       "      <th>24 Aug</th>\n",
       "      <th>25 Aug</th>\n",
       "      <th>26 Aug</th>\n",
       "      <th>27 Aug</th>\n",
       "      <th>28 Aug</th>\n",
       "      <th>29 Aug</th>\n",
       "      <th>30 Aug</th>\n",
       "      <th>Année</th>\n",
       "      <th>Feu en été</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7741</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>31.9</td>\n",
       "      <td>25.9</td>\n",
       "      <td>24.8</td>\n",
       "      <td>24.5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>31.2</td>\n",
       "      <td>28.4</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7742</td>\n",
       "      <td>8.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>34.3</td>\n",
       "      <td>24.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>26.2</td>\n",
       "      <td>19.5</td>\n",
       "      <td>25.2</td>\n",
       "      <td>34.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7743</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>31.9</td>\n",
       "      <td>21.7</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>27.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>29.8</td>\n",
       "      <td>30.3</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7823</td>\n",
       "      <td>8.3</td>\n",
       "      <td>10.2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.3</td>\n",
       "      <td>24.5</td>\n",
       "      <td>27.2</td>\n",
       "      <td>25.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>26.7</td>\n",
       "      <td>35.8</td>\n",
       "      <td>31.5</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7824</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>35.1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>26.7</td>\n",
       "      <td>20.6</td>\n",
       "      <td>26.7</td>\n",
       "      <td>36.4</td>\n",
       "      <td>31.5</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>8814</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>...</td>\n",
       "      <td>15.8</td>\n",
       "      <td>17.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>8815</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>14.1</td>\n",
       "      <td>15.5</td>\n",
       "      <td>13.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>8893</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.8</td>\n",
       "      <td>11.8</td>\n",
       "      <td>11.4</td>\n",
       "      <td>26.4</td>\n",
       "      <td>...</td>\n",
       "      <td>18.7</td>\n",
       "      <td>16.8</td>\n",
       "      <td>11.8</td>\n",
       "      <td>18.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>8894</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>26.1</td>\n",
       "      <td>...</td>\n",
       "      <td>17.9</td>\n",
       "      <td>16.4</td>\n",
       "      <td>17.2</td>\n",
       "      <td>19.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>8896</td>\n",
       "      <td>10.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>11.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>11.6</td>\n",
       "      <td>21.8</td>\n",
       "      <td>...</td>\n",
       "      <td>15.4</td>\n",
       "      <td>15.3</td>\n",
       "      <td>16.4</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2448 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      maille_safran  01 Jun  02 Jun  03 Jun  04 Jun  05 Jun  06 Jun  07 Jun  \\\n",
       "0              7741     6.6     4.4     4.5     0.1     0.1     0.0     0.5   \n",
       "1              7742     8.7     4.8     6.1     0.0     0.0     0.0     0.4   \n",
       "2              7743     8.0     2.5     2.9     0.0     0.0     0.0     0.3   \n",
       "3              7823     8.3    10.2     9.3     0.0     0.0     0.0     0.5   \n",
       "4              7824     7.8     6.5     7.4     0.0     0.0     0.0     0.4   \n",
       "...             ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2443           8814     5.2     0.3     3.0     0.9     0.9     0.9     6.2   \n",
       "2444           8815     3.6     0.3     2.1     0.5     0.4     0.2     2.5   \n",
       "2445           8893     5.4     5.0    13.0     6.8     8.4     7.8    11.8   \n",
       "2446           8894     6.3     5.2    12.1     7.6     9.6     7.6    14.0   \n",
       "2447           8896    10.6     5.5    11.4     5.3     5.4     4.1     8.8   \n",
       "\n",
       "      08 Jun  09 Jun  ...  23 Aug  24 Aug  25 Aug  26 Aug  27 Aug  28 Aug  \\\n",
       "0        0.7     1.5  ...    31.9    25.9    24.8    24.5    18.6    24.6   \n",
       "1        0.8     1.9  ...    34.3    24.8    24.3    26.2    19.5    25.2   \n",
       "2        0.5     0.9  ...    31.9    21.7    22.0    28.1    27.7    23.7   \n",
       "3        0.7     2.0  ...    33.3    24.5    27.2    25.6    19.4    26.7   \n",
       "4        0.7     1.8  ...    35.1    21.0    23.3    26.7    20.6    26.7   \n",
       "...      ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "2443     6.8    13.9  ...    15.8    17.8    15.7    20.4    16.3     0.7   \n",
       "2444     3.2    10.7  ...    14.1    15.5    13.9    17.0    12.0     0.4   \n",
       "2445    11.4    26.4  ...    18.7    16.8    11.8    18.1    11.7     3.2   \n",
       "2446    15.3    26.1  ...    17.9    16.4    17.2    19.6    12.4     3.5   \n",
       "2447    11.6    21.8  ...    15.4    15.3    16.4    18.3     1.1     0.7   \n",
       "\n",
       "      29 Aug  30 Aug  Année  Feu en été  \n",
       "0       31.2    28.4   2006           1  \n",
       "1       34.5    30.5   2006           1  \n",
       "2       29.8    30.3   2006           1  \n",
       "3       35.8    31.5   2006           1  \n",
       "4       36.4    31.5   2006           1  \n",
       "...      ...     ...    ...         ...  \n",
       "2443     0.1     0.6   2022           0  \n",
       "2444     0.1     0.7   2022           0  \n",
       "2445     4.4     9.9   2022           0  \n",
       "2446     3.5     6.8   2022           0  \n",
       "2447     1.2     3.0   2022           0  \n",
       "\n",
       "[2448 rows x 94 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcd41e75-2621-489c-956e-18742c0f5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que X et y représentent tes données et ta variable cible\n",
    "# X est un tableau numpy des caractéristiques\n",
    "# y est un tableau numpy de la variable cible binaire\n",
    "# Sélectionner les colonnes pour les fonctionnalités et la variable cible\n",
    "Xt = data.drop(columns=['Feu en été'])  # Exclure la colonne 'résultat' de X\n",
    "y = data['Feu en été']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf0a5698-d39a-47eb-8133-a8cdc34a55df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6959183673469388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xt, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser le modèle de régression logistique\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les étiquettes sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle en utilisant l'exactitude (accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f36ce23-5ea6-4a14-af11-2c14198e9e52",
   "metadata": {},
   "source": [
    "Accuracy  0,7 environ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a003e0-f16f-4622-8ff6-f51b118902bd",
   "metadata": {},
   "source": [
    "## b. Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba6b1296-e177-4807-9f22-8d2b10803ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = data.drop(columns=['Feu en été'])  # Exclure la colonne 'résultat' de X\n",
    "y = data['Feu en été']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "958d60a2-b33b-457d-8583-0af800a2be9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.763265306122449\n"
     ]
    }
   ],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test (si ce n'est pas déjà fait)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xt, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser le modèle d'arbre de décision\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les étiquettes sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle en utilisant l'exactitude (accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0439f931-0e2e-47f4-9a61-f488e92b0908",
   "metadata": {},
   "source": [
    "Accuracy  0,76 environ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ea3b3-0df1-485d-965e-cfb5db820e66",
   "metadata": {},
   "source": [
    "Essayer d'améliorer l'accuracy de l'arbre de décision en jouant sur les hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67c36246-7ebb-483b-a368-7d35a864e3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Meilleure précision (score CV): 0.7574155749256224\n",
      "Accuracy sur l'ensemble de test: 0.7673469387755102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Définir les hyperparamètres à rechercher\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialiser le modèle d'arbre de décision\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Initialiser la recherche d'hyperparamètres\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Effectuer la recherche d'hyperparamètres sur l'ensemble d'entraînement\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramètres trouvés\n",
    "print(\"Meilleurs paramètres:\", grid_search.best_params_)\n",
    "\n",
    "# Obtenir la meilleure performance trouvée lors de la validation croisée\n",
    "print(\"Meilleure précision (score CV):\", grid_search.best_score_)\n",
    "\n",
    "# Utiliser le modèle avec les meilleurs paramètres pour prédire sur l'ensemble de test\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle sur l'ensemble de test\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy sur l'ensemble de test:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab227eeb-6434-441e-b5b0-3775aab1146b",
   "metadata": {},
   "source": [
    "Améloration minime et pas terrible, mais probablement car 5 cross validation, trop importante par rapport aux données que l'on a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc2c4f9-588e-4f77-a808-020661a72240",
   "metadata": {},
   "source": [
    "## c. Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dd37fb5-0711-4c5d-9e00-5416277300bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = data.drop(columns=['Feu en été'])  # Exclure la colonne 'résultat' de X\n",
    "y = data['Feu en été']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3636a635-46bb-4112-b0d8-770ec0c637aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sur l'ensemble de test: 0.8061224489795918\n"
     ]
    }
   ],
   "source": [
    "# Initialiser le modèle Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy sur l'ensemble de test:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45761edd-9ea8-4be5-afcf-47bf54eebf2d",
   "metadata": {},
   "source": [
    "Accuracy 0,8 : de mieux en mieux !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eb753b-3842-486d-891c-20a2658c27f3",
   "metadata": {},
   "source": [
    "## d. Ridge et Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ed5073d-bcc5-4c8c-85fd-58a598fe92fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = data.drop(columns=['Feu en été'])  # Exclure la colonne 'résultat' de X\n",
    "y = data['Feu en été']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad591cc5-1bda-4aba-a1a2-e82d9ebdca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur score Ridge : 0.22733317859093932\n",
      "Meilleurs paramètres Ridge : {'alpha': 10}\n",
      "Meilleur score Lasso : 0.18952053930699891\n",
      "Meilleurs paramètres Lasso : {'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xt, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialiser le modèle Ridge\n",
    "ridge_model = Ridge()\n",
    "\n",
    "# Définir les hyperparamètres à rechercher\n",
    "param_grid_ridge = {'alpha': [0.1, 1, 10]}\n",
    "\n",
    "# Initialiser la recherche d'hyperparamètres\n",
    "grid_search_ridge = GridSearchCV(ridge_model, param_grid_ridge, cv=5)\n",
    "\n",
    "# Ajuster le modèle Ridge aux données\n",
    "grid_search_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Obtenir le meilleur modèle Ridge\n",
    "best_ridge_model = grid_search_ridge.best_estimator_\n",
    "\n",
    "# Initialiser le modèle Lasso\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Définir les hyperparamètres à rechercher\n",
    "param_grid_lasso = {'alpha': [0.1, 1, 10]}\n",
    "\n",
    "# Initialiser la recherche d'hyperparamètres\n",
    "grid_search_lasso = GridSearchCV(lasso_model, param_grid_lasso, cv=5)\n",
    "\n",
    "# Ajuster le modèle Lasso aux données\n",
    "grid_search_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Obtenir le meilleur modèle Lasso\n",
    "best_lasso_model = grid_search_lasso.best_estimator_\n",
    "\n",
    "print(\"Meilleur score Ridge :\", grid_search_ridge.best_score_)\n",
    "print(\"Meilleurs paramètres Ridge :\", grid_search_ridge.best_params_)\n",
    "print(\"Meilleur score Lasso :\", grid_search_lasso.best_score_)\n",
    "print(\"Meilleurs paramètres Lasso :\", grid_search_lasso.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8bbb4b-e865-4c8a-8c89-7deb1e89fc8c",
   "metadata": {},
   "source": [
    "# 3 - GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "571f4529-2fad-4783-9178-b03cea39532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = data.drop(columns=['Feu en été', 'maille_safran', 'Année'])  # Exclure la colonne 'résultat' de X\n",
    "y = data['Feu en été']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f9babdc-62d4-4012-aaf5-d7be28820a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             Feu en été   No. Observations:                 2448\n",
      "Model:                            GLM   Df Residuals:                     2356\n",
      "Model Family:                Binomial   Df Model:                           91\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                   -inf\n",
      "Date:                Tue, 23 Apr 2024   Deviance:                       4194.1\n",
      "Time:                        15:17:03   Pearson chi2:                 3.28e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.2986      0.492     -2.639      0.008      -2.263      -0.334\n",
      "01 Jun         0.0681      0.044      1.562      0.118      -0.017       0.154\n",
      "02 Jun        -0.0116      0.047     -0.245      0.807      -0.104       0.081\n",
      "03 Jun        -0.0793      0.042     -1.868      0.062      -0.162       0.004\n",
      "04 Jun         0.1546      0.039      3.966      0.000       0.078       0.231\n",
      "05 Jun        -0.0514      0.036     -1.440      0.150      -0.121       0.019\n",
      "06 Jun         0.0046      0.030      0.155      0.877      -0.054       0.063\n",
      "07 Jun        -0.0060      0.036     -0.165      0.869      -0.077       0.065\n",
      "08 Jun         0.0643      0.044      1.456      0.146      -0.022       0.151\n",
      "09 Jun         0.0046      0.031      0.146      0.884      -0.057       0.066\n",
      "10 Jun         0.0139      0.026      0.528      0.598      -0.038       0.065\n",
      "11 Jun        -0.0954      0.033     -2.888      0.004      -0.160      -0.031\n",
      "12 Jun         0.1244      0.033      3.797      0.000       0.060       0.189\n",
      "13 Jun        -0.0156      0.033     -0.475      0.635      -0.080       0.049\n",
      "14 Jun         0.1057      0.040      2.643      0.008       0.027       0.184\n",
      "15 Jun        -0.0238      0.042     -0.573      0.567      -0.105       0.058\n",
      "16 Jun        -0.0498      0.038     -1.326      0.185      -0.124       0.024\n",
      "17 Jun         0.0052      0.036      0.144      0.886      -0.066       0.077\n",
      "18 Jun        -0.0324      0.048     -0.677      0.498      -0.126       0.061\n",
      "19 Jun        -0.0304      0.044     -0.694      0.488      -0.116       0.055\n",
      "20 Jun        -0.0311      0.052     -0.598      0.550      -0.133       0.071\n",
      "21 Jun        -0.0588      0.024     -2.449      0.014      -0.106      -0.012\n",
      "22 Jun         0.0442      0.036      1.243      0.214      -0.025       0.114\n",
      "23 Jun         0.0140      0.036      0.388      0.698      -0.057       0.085\n",
      "24 Jun         0.1104      0.033      3.382      0.001       0.046       0.174\n",
      "25 Jun        -0.0356      0.035     -1.016      0.309      -0.104       0.033\n",
      "26 Jun        -0.0072      0.032     -0.225      0.822      -0.069       0.055\n",
      "27 Jun        -0.0265      0.036     -0.738      0.460      -0.097       0.044\n",
      "28 Jun         0.0387      0.038      1.017      0.309      -0.036       0.113\n",
      "29 Jun         0.0538      0.026      2.074      0.038       0.003       0.105\n",
      "30 Jun        -0.0115      0.026     -0.452      0.652      -0.062       0.038\n",
      "01 Jul        -0.0288      0.031     -0.932      0.352      -0.089       0.032\n",
      "02 Jul        -0.0851      0.025     -3.346      0.001      -0.135      -0.035\n",
      "03 Jul         0.1170      0.036      3.264      0.001       0.047       0.187\n",
      "04 Jul        -0.0395      0.034     -1.167      0.243      -0.106       0.027\n",
      "05 Jul         0.1042      0.043      2.438      0.015       0.020       0.188\n",
      "06 Jul         0.0761      0.032      2.354      0.019       0.013       0.139\n",
      "07 Jul         0.0522      0.031      1.672      0.095      -0.009       0.113\n",
      "08 Jul         0.0617      0.039      1.567      0.117      -0.016       0.139\n",
      "09 Jul        -0.1436      0.035     -4.067      0.000      -0.213      -0.074\n",
      "10 Jul         0.0543      0.033      1.642      0.101      -0.010       0.119\n",
      "11 Jul         0.1091      0.032      3.360      0.001       0.045       0.173\n",
      "12 Jul        -0.1075      0.033     -3.228      0.001      -0.173      -0.042\n",
      "13 Jul         0.0463      0.030      1.527      0.127      -0.013       0.106\n",
      "14 Jul        -0.1077      0.032     -3.346      0.001      -0.171      -0.045\n",
      "15 Jul        -0.0259      0.029     -0.902      0.367      -0.082       0.030\n",
      "16 Jul         0.0281      0.027      1.030      0.303      -0.025       0.081\n",
      "17 Jul        -0.0991      0.028     -3.598      0.000      -0.153      -0.045\n",
      "18 Jul         0.0532      0.034      1.567      0.117      -0.013       0.120\n",
      "19 Jul        -0.0073      0.026     -0.283      0.777      -0.058       0.043\n",
      "20 Jul        -0.0078      0.027     -0.289      0.773      -0.061       0.045\n",
      "21 Jul        -0.0459      0.023     -1.967      0.049      -0.092      -0.000\n",
      "22 Jul         0.0057      0.026      0.219      0.826      -0.045       0.056\n",
      "23 Jul        -0.0081      0.025     -0.324      0.746      -0.057       0.041\n",
      "24 Jul        -0.0534      0.031     -1.731      0.083      -0.114       0.007\n",
      "25 Jul         0.1163      0.029      4.061      0.000       0.060       0.172\n",
      "26 Jul        -0.0091      0.036     -0.254      0.800      -0.080       0.061\n",
      "27 Jul        -0.0083      0.032     -0.264      0.792      -0.070       0.054\n",
      "28 Jul         0.0460      0.023      2.011      0.044       0.001       0.091\n",
      "29 Jul        -0.0074      0.030     -0.251      0.802      -0.065       0.051\n",
      "30 Jul        -0.0134      0.027     -0.503      0.615      -0.066       0.039\n",
      "31 Jul         0.0918      0.026      3.493      0.000       0.040       0.143\n",
      "01 Aug        -0.1485      0.027     -5.546      0.000      -0.201      -0.096\n",
      "02 Aug         0.0898      0.028      3.209      0.001       0.035       0.145\n",
      "03 Aug         0.0523      0.023      2.261      0.024       0.007       0.098\n",
      "04 Aug        -0.0490      0.023     -2.156      0.031      -0.094      -0.004\n",
      "05 Aug        -0.0529      0.021     -2.573      0.010      -0.093      -0.013\n",
      "06 Aug        -0.1063      0.025     -4.193      0.000      -0.156      -0.057\n",
      "07 Aug         0.0383      0.023      1.667      0.096      -0.007       0.083\n",
      "08 Aug         0.0490      0.022      2.215      0.027       0.006       0.092\n",
      "09 Aug        -0.0287      0.023     -1.246      0.213      -0.074       0.016\n",
      "10 Aug        -0.0231      0.023     -0.990      0.322      -0.069       0.023\n",
      "11 Aug        -0.0154      0.028     -0.553      0.580      -0.070       0.039\n",
      "12 Aug         0.0563      0.028      2.041      0.041       0.002       0.110\n",
      "13 Aug        -0.0343      0.019     -1.796      0.072      -0.072       0.003\n",
      "14 Aug         0.0125      0.023      0.535      0.593      -0.033       0.058\n",
      "15 Aug         0.0197      0.031      0.641      0.521      -0.041       0.080\n",
      "16 Aug         0.0814      0.028      2.887      0.004       0.026       0.137\n",
      "17 Aug        -0.0780      0.027     -2.849      0.004      -0.132      -0.024\n",
      "18 Aug         0.0827      0.030      2.732      0.006       0.023       0.142\n",
      "19 Aug        -0.0514      0.040     -1.280      0.200      -0.130       0.027\n",
      "20 Aug         0.0862      0.027      3.182      0.001       0.033       0.139\n",
      "21 Aug        -0.0042      0.023     -0.180      0.857      -0.050       0.041\n",
      "22 Aug        -0.0780      0.029     -2.725      0.006      -0.134      -0.022\n",
      "23 Aug        -0.0319      0.031     -1.015      0.310      -0.093       0.030\n",
      "24 Aug         0.0664      0.032      2.105      0.035       0.005       0.128\n",
      "25 Aug        -0.1200      0.035     -3.392      0.001      -0.189      -0.051\n",
      "26 Aug         0.0729      0.038      1.927      0.054      -0.001       0.147\n",
      "27 Aug        -0.0519      0.025     -2.078      0.038      -0.101      -0.003\n",
      "28 Aug        -0.1123      0.028     -3.982      0.000      -0.168      -0.057\n",
      "29 Aug         0.1716      0.031      5.539      0.000       0.111       0.232\n",
      "30 Aug        -0.0210      0.023     -0.907      0.364      -0.066       0.024\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.11/site-packages/statsmodels/genmod/generalized_linear_model.py:1891: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  prsq = 1 - np.exp((self.llnull - self.llf) * (2 / self.nobs))\n"
     ]
    }
   ],
   "source": [
    "# Ajouter une constante à la matrice X pour l'intercept\n",
    "Xt = sm.add_constant(Xt)\n",
    "\n",
    "# Initialiser le modèle GLM (par exemple, une régression logistique)\n",
    "model = sm.GLM(y, Xt, family=sm.families.Binomial())\n",
    "\n",
    "# Ajuster le modèle aux données\n",
    "result = model.fit()\n",
    "\n",
    "# Afficher un résumé des résultats\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672e3d3-743d-4e37-8d22-4d2567185aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
